2024-07-11T09:27:04,945 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-07-11T09:27:04,945 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-07-11T09:27:05,011 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-07-11T09:27:05,011 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-07-11T09:27:05,012 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-07-11T09:27:05,012 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-07-11T09:27:05,067 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml
2024-07-11T09:27:05,067 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml
2024-07-11T09:27:05,234 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages
Current directory: C:\Users\theob\Code\Refactored MLSec
Temp directory: C:\Users\theob\AppData\Local\Temp
Metrics config path: C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 20
Max heap size: 8136 M
Python executable: C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\theob\Code\Refactored MLSec\model_store
Initial Models: autoencoder=autoencoder.mar
Log dir: C:\Users\theob\Code\Refactored MLSec\logs
Metrics dir: C:\Users\theob\Code\Refactored MLSec\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: C:\Users\theob\Code\Refactored MLSec\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2024-07-11T09:27:05,234 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages
Current directory: C:\Users\theob\Code\Refactored MLSec
Temp directory: C:\Users\theob\AppData\Local\Temp
Metrics config path: C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 20
Max heap size: 8136 M
Python executable: C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\theob\Code\Refactored MLSec\model_store
Initial Models: autoencoder=autoencoder.mar
Log dir: C:\Users\theob\Code\Refactored MLSec\logs
Metrics dir: C:\Users\theob\Code\Refactored MLSec\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: C:\Users\theob\Code\Refactored MLSec\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2024-07-11T09:27:05,243 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: autoencoder.mar
2024-07-11T09:27:05,243 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: autoencoder.mar
2024-07-11T09:27:05,273 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model autoencoder
2024-07-11T09:27:05,273 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model autoencoder
2024-07-11T09:27:05,273 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model autoencoder
2024-07-11T09:27:05,273 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model autoencoder
2024-07-11T09:27:05,274 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model autoencoder loaded.
2024-07-11T09:27:05,274 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model autoencoder loaded.
2024-07-11T09:27:05,274 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: autoencoder, count: 1
2024-07-11T09:27:05,274 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: autoencoder, count: 1
2024-07-11T09:27:05,283 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2024-07-11T09:27:05,283 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2024-07-11T09:27:05,285 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:05,285 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:05,373 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2024-07-11T09:27:05,373 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2024-07-11T09:27:05,373 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2024-07-11T09:27:05,373 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2024-07-11T09:27:05,375 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2024-07-11T09:27:05,375 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2024-07-11T09:27:05,375 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2024-07-11T09:27:05,375 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2024-07-11T09:27:05,376 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2024-07-11T09:27:05,376 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2024-07-11T09:27:05,610 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2024-07-11T09:27:05,610 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2024-07-11T09:27:05,701 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:27:05,701 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:27:10,172 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:10,188 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:10,188 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]20436
2024-07-11T09:27:10,189 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:10,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change null -> WORKER_STARTED
2024-07-11T09:27:10,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change null -> WORKER_STARTED
2024-07-11T09:27:10,190 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:10,197 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:10,197 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:10,205 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:10,206 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704430206
2024-07-11T09:27:10,206 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704430206
2024-07-11T09:27:10,208 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704430208
2024-07-11T09:27:10,208 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704430208
2024-07-11T09:27:10,226 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:10,531 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:10,532 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:10,532 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:10,533 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:10,552 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:10,553 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:10,553 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:10,554 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:10,554 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:10,554 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:10,555 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:10,554 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,555 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:10,555 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:10,556 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:10,556 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,556 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:10,557 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:10,557 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,557 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:10,558 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:10,558 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:10,558 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:10,559 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:10,559 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:10,559 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:10,560 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:10,560 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:10,561 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:10,561 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:10,562 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:10,562 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:10,562 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:10,563 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:10,563 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:10,564 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:10,564 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:10,564 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:10,565 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:10,565 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:10,565 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,565 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:10,566 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:10,566 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,567 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:10,567 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:10,568 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,568 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:10,569 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:10,569 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,569 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:10,570 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:10,570 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:10,570 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:10,571 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:10,571 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:10,572 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:10,572 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:10,573 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:10,573 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:10,573 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:10,555 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:10,555 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:10,580 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:10,580 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:10,581 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:10,581 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:10,581 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1720704430581
2024-07-11T09:27:10,581 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1720704430581
2024-07-11T09:27:10,582 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-07-11T09:27:10,582 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-07-11T09:27:10,584 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:10,584 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:10,584 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:10,584 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:11,586 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:11,586 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:12,768 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]22588
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:12,773 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:12,773 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:12,773 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:12,776 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704432776
2024-07-11T09:27:12,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:12,776 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704432776
2024-07-11T09:27:12,776 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704432776
2024-07-11T09:27:12,776 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704432776
2024-07-11T09:27:12,786 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:12,945 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:12,946 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:12,946 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:12,946 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:12,949 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:12,949 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:12,949 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:12,949 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:12,949 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:12,950 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:12,950 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:12,950 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:12,950 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,950 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:12,950 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:12,950 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:12,951 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:12,951 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:12,951 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,951 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:12,952 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:12,952 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:12,952 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:12,952 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:12,952 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:12,952 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:12,953 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:12,954 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:12,954 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:12,954 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:12,955 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:12,955 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:12,955 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:12,956 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:12,956 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:12,956 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:12,956 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:12,957 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:12,958 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,960 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:12,960 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:12,960 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,961 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:12,961 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:12,961 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,961 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:12,962 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:12,962 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:12,962 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:12,962 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:12,963 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:12,963 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:12,963 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:12,963 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:12,964 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:12,964 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:12,964 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:12,964 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:13,966 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:13,966 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:15,153 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]8608
2024-07-11T09:27:15,158 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:15,158 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:15,158 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:15,160 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704435160
2024-07-11T09:27:15,160 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:15,160 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704435160
2024-07-11T09:27:15,160 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704435160
2024-07-11T09:27:15,160 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704435160
2024-07-11T09:27:15,173 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:15,321 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:15,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:15,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:15,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:15,324 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:15,325 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:15,325 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:15,325 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:15,325 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:15,325 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:15,325 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:15,325 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:15,326 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,326 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:15,326 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:15,326 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:15,327 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:15,326 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:15,327 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:15,327 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,327 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:15,327 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:15,327 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:15,327 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:15,327 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:15,327 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:15,328 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:15,329 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:15,330 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:15,331 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:15,332 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:15,333 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:15,334 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:15,334 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:15,337 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:15,337 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:15,337 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:15,337 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:17,344 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:17,344 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:18,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:18,524 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:18,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]19556
2024-07-11T09:27:18,525 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:18,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:18,525 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:18,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:18,526 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:18,526 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:18,527 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704438527
2024-07-11T09:27:18,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:18,527 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704438527
2024-07-11T09:27:18,527 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704438527
2024-07-11T09:27:18,527 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704438527
2024-07-11T09:27:18,543 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:18,697 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:18,698 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:18,698 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:18,699 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:18,701 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:18,700 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:18,701 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:18,702 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:18,701 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:18,702 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:18,702 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:18,702 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:18,702 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:18,702 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:18,704 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:18,702 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,704 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:18,705 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:18,704 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:18,705 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:18,705 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:18,705 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:18,706 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-07-11T09:27:18,705 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:18,706 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-07-11T09:27:18,706 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,707 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:18,707 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:18,707 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,707 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:18,707 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:18,708 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:18,708 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:18,708 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:18,708 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:18,709 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:18,710 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:18,710 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:18,710 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:18,710 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:18,711 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:18,711 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:18,711 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:18,712 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:18,712 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:18,712 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:18,712 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,712 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:18,713 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:18,713 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,714 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:18,714 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:18,714 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,715 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:18,715 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:18,715 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,715 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:18,716 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:18,716 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:18,717 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:18,717 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:18,717 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:18,717 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:18,718 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:18,718 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:18,718 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:18,718 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:18,719 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:18,719 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:21,719 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:21,719 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:22,884 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:22,888 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:22,888 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]14692
2024-07-11T09:27:22,888 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:22,888 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:22,889 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:22,888 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:22,889 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:22,889 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:22,890 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704442890
2024-07-11T09:27:22,890 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:22,890 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704442890
2024-07-11T09:27:22,891 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704442891
2024-07-11T09:27:22,891 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704442891
2024-07-11T09:27:22,899 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:23,036 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:23,036 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:23,038 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:23,038 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:23,040 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:23,040 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:23,041 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:23,041 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:23,041 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:23,042 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:23,042 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:23,042 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:23,042 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:23,042 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,042 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:23,044 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:23,043 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:23,044 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:23,044 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:23,044 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:23,044 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:23,044 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:23,044 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:23,044 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,045 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-07-11T09:27:23,045 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-07-11T09:27:23,045 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:23,045 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:23,045 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,046 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:23,046 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:23,046 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:23,046 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:23,046 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:23,047 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:23,047 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:23,048 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:23,049 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:23,049 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:23,049 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:23,049 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:23,049 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:23,050 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,051 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:23,051 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:23,051 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,051 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:23,052 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:23,052 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,052 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:23,053 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:23,053 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,055 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:23,055 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:23,056 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:23,056 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:23,056 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:23,056 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:23,057 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:23,057 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:23,057 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:23,058 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:23,058 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:23,058 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:23,058 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:23,989 [INFO ] nioEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:54163 "GET /models HTTP/1.1" 200 3
2024-07-11T09:27:23,990 [INFO ] nioEventLoopGroup-3-1 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:MSI,timestamp:1720704443
2024-07-11T09:27:28,057 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:28,057 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:29,243 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]12532
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:29,250 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:29,250 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:29,250 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:29,251 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704449251
2024-07-11T09:27:29,251 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704449251
2024-07-11T09:27:29,252 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704449252
2024-07-11T09:27:29,252 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:29,252 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704449252
2024-07-11T09:27:29,262 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:29,427 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:29,427 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:29,428 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:29,428 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:29,430 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:29,431 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:29,431 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:29,431 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:29,431 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:29,431 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:29,431 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:29,431 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:29,431 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:29,431 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:29,431 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,432 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:29,432 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:29,432 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:29,432 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:29,432 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:29,432 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:29,432 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:29,432 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,432 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:29,433 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-07-11T09:27:29,432 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:29,433 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-07-11T09:27:29,433 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:29,433 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,433 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:29,434 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:29,434 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:29,434 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:29,434 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:29,435 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:29,436 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,437 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:29,439 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:29,440 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:29,441 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:29,441 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:37,448 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:37,448 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:38,616 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]21316
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:38,621 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:38,621 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:38,621 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:38,623 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704458623
2024-07-11T09:27:38,623 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704458623
2024-07-11T09:27:38,623 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704458623
2024-07-11T09:27:38,623 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:38,623 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704458623
2024-07-11T09:27:38,635 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:38,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:38,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:38,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:38,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:38,779 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:38,779 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:38,779 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:38,779 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:38,779 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:38,779 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:38,779 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:38,780 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:38,780 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:38,780 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:38,782 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:38,780 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,782 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:38,782 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:38,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:38,782 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:38,782 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:38,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:38,782 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:38,784 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-07-11T09:27:38,784 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-07-11T09:27:38,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:38,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:38,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:38,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:38,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:38,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:38,791 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:38,792 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:38,794 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:38,794 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:38,794 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:51,803 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:51,803 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:27:52,950 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:27:52,953 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:27:52,954 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]23844
2024-07-11T09:27:52,954 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:52,954 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:27:52,954 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:27:52,955 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:52,955 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:27:52,955 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:27:52,956 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:27:52,956 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704472956
2024-07-11T09:27:52,956 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704472956
2024-07-11T09:27:52,958 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704472958
2024-07-11T09:27:52,958 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704472958
2024-07-11T09:27:52,966 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:27:53,119 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:27:53,120 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:27:53,120 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:27:53,121 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:27:53,123 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:27:53,123 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:53,123 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:53,123 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:27:53,123 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:27:53,124 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:53,124 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:27:53,124 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:27:53,125 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:53,124 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,125 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:27:53,127 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:53,127 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:27:53,127 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:27:53,127 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:53,127 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:27:53,127 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:53,127 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:27:53,127 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:27:53,128 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-07-11T09:27:53,128 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,128 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-07-11T09:27:53,128 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:27:53,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:27:53,131 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:27:53,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:27:53,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:27:53,134 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:28:05,684 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:28:05,684 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:28:14,143 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:28:14,143 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:28:15,349 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:28:15,354 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:28:15,354 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]24868
2024-07-11T09:28:15,354 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:28:15,354 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:28:15,354 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:28:15,355 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:28:15,355 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:28:15,355 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:28:15,357 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704495357
2024-07-11T09:28:15,357 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:28:15,357 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704495357
2024-07-11T09:28:15,358 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704495358
2024-07-11T09:28:15,358 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704495358
2024-07-11T09:28:15,369 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:28:15,515 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:28:15,515 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:28:15,516 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:28:15,516 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:28:15,518 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:28:15,518 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:28:15,518 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:28:15,519 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,519 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:28:15,519 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:28:15,520 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:28:15,520 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:28:15,520 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:28:15,520 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:28:15,521 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:28:15,520 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:28:15,521 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:28:15,522 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:28:15,521 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:28:15,522 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:28:15,522 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:28:15,522 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:28:15,522 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2024-07-11T09:28:15,522 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:28:15,523 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:28:15,525 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:28:15,526 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:28:15,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:15,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:15,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:15,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:28:15,527 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:28:15,528 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:28:49,537 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:28:49,537 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:28:50,724 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:28:50,729 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:28:50,729 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]21076
2024-07-11T09:28:50,729 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:28:50,729 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:28:50,729 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:28:50,729 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:28:50,730 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:28:50,730 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:28:50,731 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704530731
2024-07-11T09:28:50,731 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:28:50,731 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704530731
2024-07-11T09:28:50,731 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704530731
2024-07-11T09:28:50,731 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704530731
2024-07-11T09:28:50,742 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:28:50,897 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:28:50,898 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:28:50,898 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:28:50,899 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:28:50,901 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:28:50,901 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:28:50,901 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:28:50,901 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:28:50,901 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:28:50,901 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:28:50,901 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:28:50,901 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,901 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:28:50,903 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:28:50,903 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:28:50,903 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:28:50,904 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:28:50,903 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:28:50,904 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:28:50,904 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,904 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:28:50,904 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:28:50,904 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:50,904 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:28:50,906 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,907 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:28:50,909 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:28:50,910 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:28:50,910 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:50,910 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:50,910 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:28:50,911 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:29:05,689 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:29:05,689 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:29:45,908 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:29:45,908 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:29:47,129 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:29:47,132 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:29:47,133 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]26112
2024-07-11T09:29:47,134 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:29:47,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:29:47,134 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:29:47,134 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:29:47,134 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:29:47,134 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:29:47,137 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704587137
2024-07-11T09:29:47,137 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704587137
2024-07-11T09:29:47,137 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:29:47,137 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704587137
2024-07-11T09:29:47,137 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704587137
2024-07-11T09:29:47,146 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:29:47,302 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:29:47,302 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:29:47,303 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:29:47,303 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:29:47,305 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:29:47,305 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:29:47,305 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:29:47,305 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:29:47,306 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:29:47,305 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:29:47,307 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:29:47,307 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,308 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:29:47,308 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:29:47,309 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,309 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:29:47,306 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:29:47,310 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:29:47,310 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:29:47,311 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,310 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:29:47,313 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:29:47,311 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:29:47,313 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:29:47,314 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:29:47,314 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:29:47,314 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:29:47,314 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:29:47,314 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:29:47,314 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:29:47,315 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2024-07-11T09:29:47,315 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2024-07-11T09:29:47,315 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:29:47,315 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:29:47,315 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:29:47,316 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:29:47,316 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:29:47,316 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:29:47,317 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:29:47,318 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:29:47,318 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:29:47,318 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:29:47,319 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:29:47,319 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:29:47,319 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:29:47,319 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:29:47,319 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,320 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:29:47,320 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:29:47,321 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,321 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:29:47,321 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:29:47,321 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:29:47,322 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:29:47,323 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:30:05,701 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:30:05,701 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:31:05,694 [ERROR] Thread-5 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:31:05,694 [ERROR] Thread-5 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:31:16,323 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:31:16,323 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:31:17,582 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:31:17,586 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:31:17,587 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]16488
2024-07-11T09:31:17,587 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:31:17,588 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:31:17,588 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:31:17,588 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:31:17,588 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:31:17,588 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:31:17,591 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704677591
2024-07-11T09:31:17,591 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:31:17,591 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704677591
2024-07-11T09:31:17,592 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704677592
2024-07-11T09:31:17,592 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704677592
2024-07-11T09:31:17,605 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:31:17,776 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:31:17,777 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:31:17,777 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:31:17,777 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:31:17,779 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:31:17,779 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:31:17,780 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:31:17,780 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:31:17,780 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:31:17,780 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:31:17,780 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:31:17,780 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:31:17,780 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,781 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:31:17,781 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:31:17,781 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:31:17,781 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:31:17,781 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:31:17,781 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:31:17,781 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:31:17,781 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:31:17,781 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:31:17,781 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:31:17,781 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:31:17,782 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:31:17,784 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:31:17,785 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:31:17,787 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:31:17,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:31:17,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:31:17,788 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:31:17,789 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:31:17,790 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:32:05,686 [ERROR] Thread-6 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:32:05,686 [ERROR] Thread-6 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:33:05,681 [ERROR] Thread-7 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:33:05,681 [ERROR] Thread-7 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:33:41,785 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:33:41,785 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\theob\AppData\Local\Programs\Python\Python311\python.exe, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml]
2024-07-11T09:33:43,010 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2024-07-11T09:33:43,014 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages/ts/configs/metrics.yaml.
2024-07-11T09:33:43,015 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - [PID]2684
2024-07-11T09:33:43,015 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:33:43,015 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch worker started.
2024-07-11T09:33:43,015 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-07-11T09:33:43,016 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:33:43,015 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Python runtime: 3.11.1
2024-07-11T09:33:43,016 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2024-07-11T09:33:43,018 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704823018
2024-07-11T09:33:43,018 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2024-07-11T09:33:43,018 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1720704823018
2024-07-11T09:33:43,018 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704823018
2024-07-11T09:33:43,018 [INFO ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1720704823018
2024-07-11T09:33:43,031 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - model_name: autoencoder, batchSize: 1
2024-07-11T09:33:43,184 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Enabled tensor cores
2024-07-11T09:33:43,185 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2024-07-11T09:33:43,186 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2024-07-11T09:33:43,187 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:33:43,186 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2024-07-11T09:33:43,187 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Backend worker process died.
2024-07-11T09:33:43,188 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:33:43,188 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 108, in load
2024-07-11T09:33:43,189 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-07-11T09:33:43,187 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-07-11T09:33:43,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:33:43,189 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-07-11T09:33:43,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:33:43,190 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2024-07-11T09:33:43,190 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-07-11T09:33:43,190 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1681) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]
	at java.lang.Thread.run(Thread.java:1589) [?:?]
2024-07-11T09:33:43,191 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:33:43,190 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,192 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:33:43,191 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: autoencoder, error: Worker died.
2024-07-11T09:33:43,193 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:33:43,192 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:33:43,193 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,193 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:33:43,193 [DEBUG] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-autoencoder_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-07-11T09:33:43,193 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:33:43,193 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:33:43,194 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
2024-07-11T09:33:43,194 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
2024-07-11T09:33:43,193 [WARN ] W-9000-autoencoder_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-07-11T09:33:43,195 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\custom_handler.py", line 5, in <module>
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from autoencoder import Autoencoder
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Temp\models\190b01102ae04d99b379d57afdccd5b7\autoencoder.py", line 4, in <module>
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     from preprocess_data import create_dataloader
2024-07-11T09:33:43,196 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'preprocess_data'
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - 
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     worker.run_server()
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-07-11T09:33:43,198 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -                             ^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -               ^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 110, in load
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-07-11T09:33:43,199 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\importlib\__init__.py", line 126, in import_module
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1128, in _find_and_load_unlocked
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
2024-07-11T09:33:43,200 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1142, in _find_and_load_unlocked
2024-07-11T09:33:43,201 [INFO ] W-9000-autoencoder_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.custom_handler'
2024-07-11T09:33:43,207 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:33:43,207 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:33:43,207 [INFO ] W-9000-autoencoder_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stdout
2024-07-11T09:33:43,207 [INFO ] W-9000-autoencoder_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-autoencoder_1.0-stderr
2024-07-11T09:34:05,707 [ERROR] Thread-8 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:34:05,707 [ERROR] Thread-8 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:35:05,701 [ERROR] Thread-9 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:35:05,701 [ERROR] Thread-9 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:36:05,688 [ERROR] Thread-10 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:36:05,688 [ERROR] Thread-10 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:37:05,693 [ERROR] Thread-11 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:37:05,693 [ERROR] Thread-11 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:38:05,697 [ERROR] Thread-12 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:38:05,697 [ERROR] Thread-12 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:39:05,696 [ERROR] Thread-13 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:39:05,696 [ERROR] Thread-13 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:40:05,702 [ERROR] Thread-14 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:40:05,702 [ERROR] Thread-14 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:41:05,710 [ERROR] Thread-15 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:41:05,710 [ERROR] Thread-15 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:42:05,690 [ERROR] Thread-16 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:42:05,690 [ERROR] Thread-16 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:43:05,706 [ERROR] Thread-17 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:43:05,706 [ERROR] Thread-17 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:44:05,690 [ERROR] Thread-18 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:44:05,690 [ERROR] Thread-18 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:45:05,704 [ERROR] Thread-19 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:45:05,704 [ERROR] Thread-19 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:46:05,692 [ERROR] Thread-20 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:46:05,692 [ERROR] Thread-20 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:47:05,694 [ERROR] Thread-21 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:47:05,694 [ERROR] Thread-21 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:48:05,692 [ERROR] Thread-22 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:48:05,692 [ERROR] Thread-22 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:49:05,699 [ERROR] Thread-23 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:49:05,699 [ERROR] Thread-23 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:50:05,690 [ERROR] Thread-24 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:50:05,690 [ERROR] Thread-24 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:51:05,697 [ERROR] Thread-25 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:51:05,697 [ERROR] Thread-25 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:52:05,686 [ERROR] Thread-26 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:52:05,686 [ERROR] Thread-26 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:53:05,697 [ERROR] Thread-27 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:53:05,697 [ERROR] Thread-27 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:54:05,691 [ERROR] Thread-28 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:54:05,691 [ERROR] Thread-28 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:55:05,704 [ERROR] Thread-29 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:55:05,704 [ERROR] Thread-29 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:56:05,681 [ERROR] Thread-30 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:56:05,681 [ERROR] Thread-30 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:57:05,709 [ERROR] Thread-31 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:57:05,709 [ERROR] Thread-31 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:58:05,704 [ERROR] Thread-32 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:58:05,704 [ERROR] Thread-32 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:59:05,706 [ERROR] Thread-33 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2024-07-11T09:59:05,706 [ERROR] Thread-33 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\theob\AppData\Local\Programs\Python\Python311\Lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

