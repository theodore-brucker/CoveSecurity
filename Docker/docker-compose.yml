services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - kafka_network

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONSUMER_MAX_POLL_INTERVAL_MS: 900000
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_OPTS: "-Djava.net.preferIPv4Stack=true"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - zookeeper
    networks:
      kafka_network:
        aliases:
          - kafka

  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      echo -e 'Creating kafka topics'
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list

      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic raw_data --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic processed_data --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic predictions --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic training_data --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic labeled_data --replication-factor 1 --partitions 1
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      "
    networks:
      - kafka_network

  torchserve:
    build:
      context: ./model_store
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
      - "8081:8081"
      - "8082:8082"
    environment:
      - EARLY_STOPPING_THRESHOLD=.001
      - NUM_EPOCHS=25
      - SEQUENCE_LENGTH=16
      - FEATURE_COUNT=12
      - MODEL_STORE_PATH=/home/model-server/model-store/
    volumes:
      - ./model_store:/home/model-server/model-store
      - scaler_data:/home/model-server/scaler_data
    networks:
      - kafka_network

  web_backend:
    build:
      context: ./web/backend
    volumes:
      - ./web/backend:/app
      - training_data:/app/training_data
    environment:
      - KAFKA_BROKER=kafka:9092
      - RAW_TOPIC=raw_data
      - PROCESSED_TOPIC=processed_data
      - PREDICTION_TOPIC=predictions
      - TRAINING_TOPIC=training_data
      - LABELED_TOPIC=labeled_data
      - MAX_RETRIES=5
      - RETRY_DELAY=2
      - DATA_PROCESSING_URL=http://172.17.0.1:5001
      - MONGO_URI=mongodb://mongodb:27017/
      - training_data:/app/training_data
    ports:
      - "5000:5000"
    networks:
      kafka_network:
        aliases:
          - web_backend
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - kafka
      - mongodb

  web_frontend:
    build:
      context: ./web/frontend
      args:
        - REACT_APP_BACKEND_URL=http://web_backend:5000
    volumes:
      - ./web/frontend:/app
    ports:
      - "3000:3000"
    networks:
      - kafka_network

  data_processing:
    build:
      context: ./data_processing
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
    volumes:
      - scaler_data:/app/scaler_data
      - training_data:/app/training_data
    environment:
      - KAFKA_BROKER=localhost:29092
      - RAW_TOPIC=raw_data
      - PROCESSED_TOPIC=processed_data
      - PREDICTIONS_TOPIC=predictions
      - TRAINING_TOPIC=training_data
      - CAPTURE_INTERFACE=eth0
      - TORCHSERVE_REQUESTS=http://localhost:8080
      - TORCHSERVE_MANAGEMENT=http://localhost:8081
      - TORCHSERVE_METRICS=http://localhost:8082
      - ANOMALY_THRESHOLD=.5
      - WEB_BACKEND_URL=http://localhost:5000
      - MODEL_NAME=transformer_autoencoder
      - MONGO_URI=mongodb://mongodb:27017/
      - training_data:/app/training_data
      - SEQUENCE_LENGTH=16
      - FEATURE_COUNT=12
      - FLASK_PORT=5001
    depends_on:
      - kafka
      - torchserve
      - web_backend
      - mongodb
    extra_hosts:
      - "host.docker.internal:host-gateway"

  mongodb:
    build:
      context: ./database
      dockerfile: Dockerfile
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - ./database/logs:/var/log/mongodb
    networks:
      - kafka_network
    command: ["mongod", "--config", "/etc/mongod.conf"]

  mongo-express:
    image: mongo-express
    ports:
      - "28081:8081"
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://mongodb:27017/admin
      ME_CONFIG_BASICAUTH_USERNAME: root
      ME_CONFIG_BASICAUTH_PASSWORD: example
    networks:
      - kafka_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - mongodb
    restart: always

networks:
  kafka_network:
    driver: bridge

volumes:
  scaler_data:
  training_data:
  mongodb_data: